{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0c8d44c-598c-4df5-8d57-e6b485ef9d5b",
   "metadata": {},
   "source": [
    "# Análisis de Agrupación para Datos de Samsung\n",
    "\n",
    "Este notebook implementa un algoritmo de agrupación (clustering) para analizar patrones en el conjunto de datos de Samsung. Se incluye una justificación del algoritmo, descripción del diseño, evaluación del modelo, así como visualizaciones personalizadas e interpretación de resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1382d1-9cd8-43c7-a4de-2e498c5c0d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('dark_background')\n",
    "sns.set_palette('magma')\n",
    "plt.rcParams['figure.figsize'] = (14, 9)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b3550d-2df9-4fd0-be3a-b327bdb62d0c",
   "metadata": {},
   "source": [
    "## 1. Carga y Exploración de Datos\n",
    "\n",
    "Primero, cargamos el conjunto de datos de Samsung y exploramos su estructura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610ad62c-559c-419e-b122-88facd41058c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset\n",
    "df = pd.read_csv('samsung.csv')\n",
    "\n",
    "# Mostrar las primeras filas\n",
    "print('Primeras 5 filas del dataset:')\n",
    "display(df.head())\n",
    "\n",
    "# Información del dataset\n",
    "print('\nInformación del dataset:')\n",
    "df.info()\n",
    "\n",
    "# Estadísticas descriptivas\n",
    "print('\nEstadísticas descriptivas:')\n",
    "display(df.describe())\n",
    "\n",
    "# Verificar valores nulos\n",
    "print('\nValores nulos por columna:')\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Eliminar filas con valores nulos si existen\n",
    "df_clean = df.dropna()\n",
    "print(f'\nFilas originales: {df.shape[0]}, Filas después de eliminar nulos: {df_clean.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176fbae4-0cd2-4021-85a1-1149c1965f07",
   "metadata": {},
   "source": [
    "## 2. Análisis Exploratorio de Datos (EDA)\n",
    "\n",
    "Realizamos un análisis exploratorio para entender mejor las distribuciones y relaciones entre las variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b3550d-2df9-4fd0-be3a-b327bdb62d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar solo columnas numéricas para el análisis\n",
    "numeric_df = df_clean.select_dtypes(include=[np.number])\n",
    "\n",
    "# Matriz de correlación\n",
    "plt.figure(figsize=(16, 14))\n",
    "correlation_matrix = numeric_df.corr()\n",
    "\n",
    "# Crear una máscara para el triángulo superior\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "\n",
    "# Generar un mapa de calor con la máscara\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=False, cmap='magma', linewidths=0.5, vmin=-1, vmax=1)\n",
    "plt.title('Matriz de Correlación (Triángulo Inferior)', fontsize=18)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Distribución de variables\n",
    "# Seleccionar un subconjunto de columnas si hay demasiadas\n",
    "if numeric_df.shape[1] > 10:\n",
    "    # Seleccionar las 10 columnas con mayor varianza\n",
    "    variances = numeric_df.var().sort_values(ascending=False)\n",
    "    top_columns = variances.index[:10].tolist()\n",
    "    plot_df = numeric_df[top_columns]\n",
    "else:\n",
    "    plot_df = numeric_df\n",
    "\n",
    "# Crear histogramas para cada variable\n",
    "fig, axes = plt.subplots(nrows=int(np.ceil(plot_df.shape[1]/3)), ncols=3, figsize=(18, 15))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, column in enumerate(plot_df.columns):\n",
    "    if i < len(axes):\n",
    "        sns.histplot(plot_df[column], kde=True, ax=axes[i], color='magenta')\n",
    "        axes[i].set_title(f'Distribución de {column}', fontsize=14)\n",
    "        axes[i].set_xlabel(column, fontsize=12)\n",
    "        axes[i].set_ylabel('Frecuencia', fontsize=12)\n",
    "\n",
    "# Ocultar ejes vacíos\n",
    "for j in range(i + 1, len(axes)):\n",
    "    axes[j].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Gráfico de dispersión de pares para las variables con mayor varianza\n",
    "if numeric_df.shape[1] > 5:\n",
    "    # Seleccionar las 5 columnas con mayor varianza\n",
    "    top5_columns = variances.index[:5].tolist()\n",
    "    pair_plot_df = numeric_df[top5_columns]\n",
    "else:\n",
    "    pair_plot_df = numeric_df\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "sns.pairplot(pair_plot_df, diag_kind='kde', plot_kws={'alpha': 0.6, 's': 80, 'edgecolor': 'k'})\n",
    "plt.suptitle('Gráficos de Dispersión entre Pares de Variables', y=1.02, fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Análisis de outliers con boxplots\n",
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "# Crear un boxplot para cada variable\n",
    "ax = sns.boxplot(data=plot_df, palette='magma')\n",
    "plt.title('Detección de Outliers por Variable', fontsize=16)\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b3550d-2df9-4fd0-be3a-b327bdb62d0d",
   "metadata": {},
   "source": [
    "## 3. Justificación del Algoritmo\n",
    "\n",
    "Para este problema de agrupación no supervisada, he seleccionado el algoritmo K-means como método principal por las siguientes razones:\n",
    "\n",
    "1. **Eficiencia computacional**: K-means es un algoritmo eficiente que escala bien con conjuntos de datos grandes, lo que es importante para analizar datos de dispositivos Samsung que pueden ser voluminosos.\n",
    "\n",
    "2. **Interpretabilidad**: Los centroides de K-means proporcionan una representación clara y comprensible de cada grupo, facilitando la interpretación de los patrones identificados.\n",
    "\n",
    "3. **Flexibilidad en la forma de los clusters**: Aunque K-means asume clusters esféricos, esta limitación puede mitigarse mediante la transformación adecuada de los datos o el uso de técnicas de reducción de dimensionalidad como PCA antes de aplicar el algoritmo.\n",
    "\n",
    "4. **Facilidad para determinar el número óptimo de clusters**: Existen métodos bien establecidos como el método del codo, la puntuación de silueta y el índice Davies-Bouldin para determinar el número óptimo de clusters.\n",
    "\n",
    "5. **Aplicabilidad a datos de comportamiento de usuario**: K-means es particularmente útil para segmentar usuarios basándose en patrones de comportamiento, lo que es relevante para datos de dispositivos Samsung.\n",
    "\n",
    "Además, compararemos K-means con otros algoritmos de clustering (DBSCAN y Agglomerative Clustering) para validar nuestra elección y explorar diferentes perspectivas de agrupación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b3550d-2df9-4fd0-be3a-b327bdb62d0e",
   "metadata": {},
   "source": [
    "## 4. Preparación de Datos para Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b3550d-2df9-4fd0-be3a-b327bdb62d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar las variables para el clustering\n",
    "# Usar todas las variables numéricas o un subconjunto según el análisis exploratorio\n",
    "X = numeric_df.copy()\n",
    "\n",
    "# Escalar los datos - Probar diferentes escaladores\n",
    "scalers = {\n",
    "    'StandardScaler': StandardScaler(),\n",
    "    'MinMaxScaler': MinMaxScaler(),\n",
    "    'RobustScaler': RobustScaler()\n",
    "}\n",
    "\n",
    "scaled_data = {}\n",
    "for name, scaler in scalers.items():\n",
    "    scaled_data[name] = scaler.fit_transform(X)\n",
    "    \n",
    "# Por defecto, usaremos StandardScaler para el análisis principal\n",
    "X_scaled = scaled_data['StandardScaler']\n",
    "\n",
    "print(f'Dimensiones de los datos escalados: {X_scaled.shape}')\n",
    "\n",
    "# Reducción de dimensionalidad con PCA para visualización\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Varianza explicada\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "cumulative_variance = np.cumsum(explained_variance)\n",
    "\n",
    "print('\nVarianza explicada por componente:')\n",
    "for i, var in enumerate(explained_variance):\n",
    "    print(f'Componente {i+1}: {var:.4f} ({cumulative_variance[i]:.4f} acumulado)')\n",
    "\n",
    "# Visualizar la varianza explicada\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(1, len(explained_variance) + 1), explained_variance, alpha=0.8, color='magenta', label='Varianza individual')\n",
    "plt.step(range(1, len(cumulative_variance) + 1), cumulative_variance, where='mid', label='Varianza acumulada', color='cyan')\n",
    "plt.axhline(y=0.8, color='r', linestyle='--', label='Umbral 80%')\n",
    "plt.xlabel('Número de Componentes', fontsize=14)\n",
    "plt.ylabel('Ratio de Varianza Explicada', fontsize=14)\n",
    "plt.title('Varianza Explicada por Componentes Principales', fontsize=16)\n",
    "plt.legend(loc='best', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualización de datos en espacio PCA 3D\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "scatter = ax.scatter(X_pca[:, 0], X_pca[:, 1], X_pca[:, 2], c='magenta', s=50, alpha=0.6, edgecolors='w')\n",
    "\n",
    "ax.set_title('Visualización 3D de Datos con PCA', fontsize=16)\n",
    "ax.set_xlabel(f'PC1 ({explained_variance[0]:.2%})', fontsize=14)\n",
    "ax.set_ylabel(f'PC2 ({explained_variance[1]:.2%})', fontsize=14)\n",
    "ax.set_zlabel(f'PC3 ({explained_variance[2]:.2%})', fontsize=14)\n",
    "\n",
    "# Añadir una cuadrícula\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualización interactiva con Plotly (opcional)\n",
    "try:\n",
    "    fig = px.scatter_3d(\n",
    "        x=X_pca[:, 0], y=X_pca[:, 1], z=X_pca[:, 2],\n",
    "        opacity=0.7,\n",
    "        title='Visualización 3D Interactiva de Datos con PCA',\n",
    "        labels={'x': f'PC1 ({explained_variance[0]:.2%})',\n",
    "                'y': f'PC2 ({explained_variance[1]:.2%})',\n",
    "                'z': f'PC3 ({explained_variance[2]:.2%})'}\n",
    "    )\n",
    "    \n",
    "    fig.update_traces(marker=dict(size=5, line=dict(width=1, color='white')))\n",
    "    fig.update_layout(\n",
    "        template='plotly_dark',\n",
    "        scene=dict(\n",
    "            xaxis=dict(showbackground=False),\n",
    "            yaxis=dict(showbackground=False),\n",
    "            zaxis=dict(showbackground=False)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "except:\n",
    "    print('Plotly no está disponible o no se pudo generar la visualización interactiva.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b3550d-2df9-4fd0-be3a-b327bdb62d0g",
   "metadata": {},
   "source": [
    "## 5. Descripción del Diseño del Modelo\n",
    "\n",
    "Implementaremos un enfoque sistemático para el clustering:\n",
    "\n",
    "1. **Determinación del número óptimo de clusters**: Utilizaremos múltiples métodos (método del codo, puntuación de silueta, índice Davies-Bouldin) para determinar el número óptimo de clusters.\n",
    "\n",
    "2. **Aplicación de K-means**: Implementaremos K-means con el número óptimo de clusters determinado.\n",
    "\n",
    "3. **Evaluación del modelo**: Evaluaremos la calidad del clustering utilizando métricas internas como la puntuación de silueta y el índice Davies-Bouldin.\n",
    "\n",
    "4. **Comparación con otros algoritmos**: Compararemos K-means con DBSCAN y Agglomerative Clustering para validar nuestra elección.\n",
    "\n",
    "5. **Interpretación de clusters**: Analizaremos las características de cada cluster para entender los patrones identificados."
   ]
  },
   {
    "cell_type": "code",
    "execution_count": null,
    "id": "g1b3550d-2df9-4fd0-be3a-b327bdb62d0h",
    "metadata": {},
    "outputs": [],
    "source": [
     "# 1. Determinación del número óptimo de clusters\n",
     "\n",
     "# Método del codo\n",
     "inertia_values = []\n",
     "silhouette_scores = []\n",
     "davies_bouldin_scores = []\n",
     "calinski_harabasz_scores = []\n",
     "\n",
     "k_range = range(2, 15)\n",
     "\n",
     "for k in k_range:\n",
     "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
     "    kmeans.fit(X_scaled)\n",
     "    inertia_values.append(kmeans.inertia_)\n",
     "    \n",
     "    # Calcular métricas de evaluación\n",
     "    labels = kmeans.labels_\n",
     "    silhouette_scores.append(silhouette_score(X_scaled, labels))\n",
     "    davies_bouldin_scores.append(davies_bouldin_score(X_scaled, labels))\n",
     "    calinski_harabasz_scores.append(calinski_harabasz_score(X_scaled, labels))\n",
     "\n",
     "# Visualizar resultados\n",
     "fig, axes = plt.subplots(2, 2, figsize=(18, 14))\n",
     "\n",
     "# Método del codo (Inertia)\n",
     "axes[0, 0].plot(k_range, inertia_values, marker='o', linestyle='-', linewidth=2, markersize=8, color='magenta')\n",
     "axes[0, 0].set_title('Método del Codo (Inertia)', fontsize=16)\n",
     "axes[0, 0].set_xlabel('Número de Clusters (k)', fontsize=14)\n",
     "axes[0, 0].set_ylabel('Inertia', fontsize=14)\n",
     "axes[0, 0].grid(True, alpha=0.3)\n",
     "\n",
     "# Puntuación de Silueta\n",
     "axes[0, 1].plot(k_range, silhouette_scores, marker='o', linestyle='-', linewidth=2, markersize=8, color='cyan')\n",
     "axes[0, 1].set_title('Puntuación de Silueta', fontsize=16)\n",
     "axes[0, 1].set_xlabel('Número de Clusters (k)', fontsize=14)\n",
     "axes[0, 1].set_ylabel('Puntuación de Silueta', fontsize=14)\n",
     "axes[0, 1].grid(True, alpha=0.3)\n",
     "\n",
     "# Índice Davies-Bouldin\n",
     "axes[1, 0].plot(k_range, davies_bouldin_scores, marker='o', linestyle='-', linewidth=2, markersize=8, color='yellow')\n",
     "axes[1, 0].set_title('Índice Davies-Bouldin', fontsize=16)\n",
     "axes[1, 0].set_xlabel('Número de Clusters (k)', fontsize=14)\n",
     "axes[1, 0].set_ylabel('Índice Davies-Bouldin', fontsize=14)\n",
     "axes[1, 0].grid(True, alpha=0.3)\n",
     "\n",
     "# Índice Calinski-Harabasz\n",
     "axes[1, 1].plot(k_range, calinski_harabasz_scores, marker='o', linestyle='-', linewidth=2, markersize=8, color='lime')\n",
     "axes[1, 1].set_title('Índice Calinski-Harabasz', fontsize=16)\n",
     "axes[1, 1].set_xlabel('Número de Clusters (k)', fontsize=14)\n",
     "axes[1, 1].set_ylabel('Índice Calinski-Harabasz', fontsize=14)\n",
     "axes[1, 1].grid(True, alpha=0.3)\n",
     "\n",
     "plt.tight_layout()\n",
     "plt.show()\n",
     "\n",
     "# Determinar el número óptimo de clusters\n",
     "# Para el método del codo, buscamos el punto de inflexión\n",
     "# Para la puntuación de silueta, buscamos el máximo\n",
     "# Para el índice Davies-Bouldin, buscamos el mínimo\n",
     "# Para el índice Calinski-Harabasz, buscamos el máximo\n",
     "\n",
     "optimal_k_silhouette = k_range[np.argmax(silhouette_scores)]\n",
     "optimal_k_davies = k_range[np.argmin(davies_bouldin_scores)]\n",
     "optimal_k_calinski = k_range[np.argmax(calinski_harabasz_scores)]\n",
     "\n",
     "print(f'Número óptimo de clusters según la puntuación de silueta: {optimal_k_silhouette}')\n",
     "print(f'Número óptimo de clusters según el índice Davies-Bouldin: {optimal_k_davies}')\n",
     "print(f'Número óptimo de clusters según el índice Calinski-Harabasz: {optimal_k_calinski}')\n",
     "\n",
     "# Visualización de silueta para el número óptimo de clusters\n",
     "optimal_k = optimal_k_silhouette  # Podemos elegir cualquiera de los tres o hacer una votación\n",
     "\n",
     "# Crear un modelo K-means con el número óptimo de clusters\n",
     "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
     "cluster_labels = kmeans.fit_predict(X_scaled)\n",
     "\n",
     "# Visualizar la silueta\n",
     "plt.figure(figsize=(12, 8))\n",
     "visualizer = SilhouetteVisualizer(kmeans, colors='magma', is_fitted=True)\n",
     "visualizer.fit(X_scaled)\n",
     "visualizer.show()\n",
     "\n",
     "# Añadir los clusters al DataFrame original\n",
     "df_clean['Cluster'] = cluster_labels\n",
     "\n",
     "# Mostrar el tamaño de cada cluster\n",
     "cluster_sizes = df_clean['Cluster'].value_counts().sort_index()\n",
     "print('\nTamaño de cada cluster:')\n",
     "for cluster, size in cluster_sizes.items():\n",
     "    print(f'Cluster {cluster}: {size} muestras ({size/len(df_clean):.2%})')"
    ]
   },
   {
    "cell_type": "markdown",
    "id": "h1b3550d-2df9-4fd0-be3a-b327bdb62d0i",
    "metadata": {},
    "source": [
     "## 6. Visualización de Clusters e Interpretación"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "id": "i1b3550d-2df9-4fd0-be3a-b327bdb62d0j",
    "metadata": {},
    "outputs": [],
    "source": [
     "# Visualización de clusters en espacio PCA\n",
     "# Aplicar PCA a los datos escalados\n",
     "pca = PCA(n_components=3)\n",
     "X_pca = pca.fit_transform(X_scaled)\n",
     "\n",
     "# Crear un DataFrame con los componentes principales y los clusters\n",
     "pca_df = pd.DataFrame(\n",
     "    data=X_pca,\n",
     "    columns=['PC1', 'PC2', 'PC3']\n",
     ")\n",
     "pca_df['Cluster'] = cluster_labels\n",
     "\n",
     "# Visualización 3D de clusters\n",
     "fig = plt.figure(figsize=(14, 12))\n",
     "ax = fig.add_subplot(111, projection='3d')\n",
     "\n",
     "# Crear un mapa de colores personalizado\n",
     "colors = plt.cm.magma(np.linspace(0, 1, optimal_k))\n",
     "\n",
     "for cluster in range(optimal_k):\n",
     "    # Filtrar puntos del cluster actual\n",
     "    cluster_points = pca_df[pca_df['Cluster'] == cluster]\n",
     "    \n",
     "    # Graficar puntos\n",
     "    ax.scatter(\n",
     "        cluster_points['PC1'],\n",
     "        cluster_points['PC2'],\n",
     "        cluster_points['PC3'],\n",
     "        s=50,\n",
     "        color=colors[cluster],\n",
     "        label=f'Cluster {cluster}',\n",
     "        alpha=0.7,\n",
     "        edgecolors='w'\n",
     "    )\n",
     "    \n",
     "    # Graficar centroides (transformados al espacio PCA)\n",
     "    centroid_scaled = kmeans.cluster_centers_[cluster].reshape(1, -1)\n",
     "    centroid_pca = pca.transform(centroid_scaled)\n",
     "    \n",
     "    ax.scatter(\n",
     "        centroid_pca[:, 0],\n",
     "        centroid_pca[:, 1],\n",
     "        centroid_pca[:, 2],\n",
     "        s=200,\n",
     "        color=colors[cluster],\n",
     "        marker='*',\n",
     "        edgecolors='k',\n",
     "        linewidth=2,\n",
     "        alpha=1.0\n",
     "    )\n",
     "\n",
     "ax.set_title(f'Visualización 3D de Clusters (K={optimal_k})', fontsize=16)\n",
     "ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})', fontsize=14)\n",
     "ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})', fontsize=14)\n",
     "ax.set_zlabel(f'PC3 ({pca.explained_variance_ratio_[2]:.2%})', fontsize=14)\n",
     "\n",
     "# Añadir leyenda\n",
     "ax.legend(title='Clusters', title_fontsize=12, fontsize=10, loc='best')\n",
     "\n",
     "# Añadir una cuadrícula\n",
     "ax.grid(True, alpha=0.3)\n",
     "\n",
     "plt.tight_layout()\n",
     "plt.show()\n",
     "\n",
     "# Visualización interactiva con Plotly (opcional)\n",
     "try:\n",
     "    # Crear un DataFrame para Plotly\n",
     "    plotly_df = pca_df.copy()\n",
     "    plotly_df['Cluster'] = plotly_df['Cluster'].astype(str)\n",
     "    \n",
     "    # Crear la figura 3D\n",
     "    fig = px.scatter_3d(\n",
     "        plotly_df,\n",
     "        x='PC1',\n",
     "        y='PC2',\n",
     "        z='PC3',\n",
     "        color='Cluster',\n",
     "        opacity=0.7,\n",
     "        title=f'Visualización 3D Interactiva de Clusters (K={optimal_k})',\n",
     "        labels={'PC1': f'PC1 ({pca.explained_variance_ratio_[0]:.2%})',\n",
     "                'PC2': f'PC2 ({pca.explained_variance_ratio_[1]:.2%})',\n",
     "                'PC3': f'PC3 ({pca.explained_variance_ratio_[2]:.2%})'}\n",
     "    )\n",
     "    \n",
     "    # Añadir centroides\n",
     "    for cluster in range(optimal_k):\n",
     "        centroid_scaled = kmeans.cluster_centers_[cluster].reshape(1, -1)\n",
     "        centroid_pca = pca.transform(centroid_scaled)\n",
     "        \n",
     "        fig.add_trace(\n",
     "            go.Scatter3d(\n",
     "                x=centroid_pca[:, 0],\n",
     "                y=centroid_pca[:, 1],\n",
     "                z=centroid_pca[:, 2],\n",
     "                mode='markers',\n",
     "                marker=dict(\n",
     "                    size=15,\n",
     "                    symbol='star',\n",
     "                    color=cluster,\n",
     "                    line=dict(width=2, color='black')\n",
     "                ),\n",
     "                name=f'Centroide {cluster}'\n",
     "            )\n",
     "        )\n",
     "    \n",
     "    fig.update_layout(\n",
     "        template='plotly_dark',\n",
     "        scene=dict(\n",
     "            xaxis=dict(showbackground=False),\n",
     "            yaxis=dict(showbackground=False),\n",
     "            zaxis=dict(showbackground=False)\n",
     "        )\n",
     "    )\n",
     "    \n",
     "    fig.show()\n",
     "except:\n",
     "    print('Plotly no está disponible o no se pudo generar la visualización interactiva.')\n",
     "\n",
     "# Visualización 2D de clusters (PC1 vs PC2)\n",
     "plt.figure(figsize=(14, 10))\n",
     "\n",
     "for cluster in range(optimal_k):\n",
     "    # Filtrar puntos del cluster actual\n",
     "    cluster_points = pca_df[pca_df['Cluster'] == cluster]\n",
     "    \n",
     "    # Graficar puntos\n",
     "    plt.scatter(\n",
     "        cluster_points['PC1'],\n",
     "        cluster_points['PC2'],\n",
     "        s=80,\n",
     "        color=colors[cluster],\n",
     "        label=f'Cluster {cluster}',\n",
     "        alpha=0.7,\n",
     "        edgecolors='w'\n",
     "    )\n",
     "    \n",
     "    # Graficar centroides (transformados al espacio PCA)\n",
     "    centroid_scaled = kmeans.cluster_centers_[cluster].reshape(1, -1)\n",
     "    centroid_pca = pca.transform(centroid_scaled)\n",
     "    \n",
     "    plt.scatter(\n",
     "        centroid_pca[:, 0],\n",
     "        centroid_pca[:, 1],\n",
     "        s=200,\n",
     "        color=colors[cluster],\n",
     "        marker='*',\n",
     "        edgecolors='k',\n",
     "        linewidth=2,\n",
     "        alpha=1.0\n",
     "    )\n",
     "\n",
     "plt.title(f'Visualización 2D de Clusters (K={optimal_k})', fontsize=16)\n",
     "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})', fontsize=14)\n",
     "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})', fontsize=14)\n",
     "plt.grid(True, alpha=0.3)\n",
     "plt.legend(title='Clusters', title_fontsize=12, fontsize=10, loc='best')\n",
     "plt.tight_layout()\n",
     "plt.show()"
    ]
   }
  ],
  "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
