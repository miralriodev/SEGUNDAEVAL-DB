{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An√°lisis Multivariante para Decisiones Inmobiliarias: Comprar vs Alquilar\n",
    "\n",
    "Este notebook presenta un an√°lisis avanzado de los factores que influyen en la decisi√≥n de comprar o alquilar una vivienda, utilizando t√©cnicas de an√°lisis multivariante y aprendizaje no supervisado para identificar patrones y relaciones complejas en los datos.\n",
    "\n",
    "## Objetivos:\n",
    "- Realizar un an√°lisis exploratorio profundo de factores econ√≥micos y personales\n",
    "- Implementar t√©cnicas de reducci√≥n de dimensionalidad (PCA, t-SNE)\n",
    "- Identificar perfiles de decisi√≥n mediante t√©cnicas de clustering\n",
    "- Visualizar relaciones complejas entre variables\n",
    "- Generar recomendaciones personalizadas basadas en perfiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importaci√≥n de Librer√≠as y Configuraci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librer√≠as fundamentales\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Preprocesamiento y reducci√≥n de dimensionalidad\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.decomposition import PCA, KernelPCA, SparsePCA, TruncatedSVD\n",
    "from sklearn.manifold import TSNE, MDS, Isomap, LocallyLinearEmbedding\n",
    "\n",
    "# Algoritmos de clustering\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN, SpectralClustering\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "\n",
    "# Configuraci√≥n\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_theme(style='whitegrid', palette='viridis')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Configuraci√≥n para reproducibilidad\n",
    "np.random.seed(42)\n",
    "\n",
    "print('‚úÖ Librer√≠as importadas correctamente')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335321c0",
   "metadata": {},
   "source": [
    "## 2. Carga y Exploraci√≥n Inicial de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a06af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el conjunto de datos\n",
    "try:\n",
    "    # Intentar cargar desde diferentes fuentes posibles\n",
    "    try:\n",
    "        df = pd.read_csv('datos_inmobiliarios.csv')\n",
    "        print('Datos cargados desde datos_inmobiliarios.csv')\n",
    "    except FileNotFoundError:\n",
    "        try:\n",
    "            df = pd.read_csv('alquilar_comprar.csv')\n",
    "            print('Datos cargados desde alquilar_comprar.csv')\n",
    "        except FileNotFoundError:\n",
    "            # Si no se encuentra el archivo, crear datos sint√©ticos para demostraci√≥n\n",
    "            print('Archivos de datos no encontrados. Creando datos sint√©ticos para demostraci√≥n...')\n",
    "            \n",
    "            # Generar datos sint√©ticos para demostraci√≥n\n",
    "            np.random.seed(42)\n",
    "            n_samples = 500\n",
    "            \n",
    "            # Factores econ√≥micos\n",
    "            ingresos = np.random.normal(5000, 1500, n_samples)\n",
    "            precio_vivienda = np.random.normal(250000, 75000, n_samples)\n",
    "            precio_alquiler = np.random.normal(1200, 400, n_samples)\n",
    "            tasa_interes = np.random.normal(3.5, 0.8, n_samples)\n",
    "            inflacion = np.random.normal(2.5, 0.5, n_samples)\n",
    "            \n",
    "            # Factores personales\n",
    "            edad = np.random.normal(35, 10, n_samples)\n",
    "            tiempo_permanencia = np.random.normal(7, 3, n_samples)\n",
    "            estabilidad_laboral = np.random.normal(7, 2, n_samples)\n",
    "            preferencia_propiedad = np.random.normal(6, 2, n_samples)\n",
    "            aversion_riesgo = np.random.normal(5, 2, n_samples)\n",
    "            \n",
    "            # Factores de mercado\n",
    "            apreciacion_propiedad = np.random.normal(3.0, 1.0, n_samples)\n",
    "            oferta_vivienda = np.random.normal(5, 2, n_samples)\n",
    "            demanda_vivienda = np.random.normal(6, 2, n_samples)\n",
    "            tendencia_mercado = np.random.normal(0, 1, n_samples)\n",
    "            \n",
    "            # Factores de ubicaci√≥n\n",
    "            calidad_ubicacion = np.random.normal(7, 2, n_samples)\n",
    "            acceso_servicios = np.random.normal(6, 2, n_samples)\n",
    "            distancia_trabajo = np.random.normal(15, 8, n_samples)\n",
    "            \n",
    "            # Factores fiscales y legales\n",
    "            beneficios_fiscales = np.random.normal(4, 2, n_samples)\n",
    "            costos_mantenimiento = np.random.normal(300, 100, n_samples)\n",
    "            \n",
    "            # Variables categ√≥ricas\n",
    "            estado_civil = np.random.choice(['Soltero', 'Casado', 'Divorciado'], n_samples, p=[0.4, 0.5, 0.1])\n",
    "            tiene_hijos = np.random.choice(['S√≠', 'No'], n_samples, p=[0.6, 0.4])\n",
    "            tipo_empleo = np.random.choice(['Tiempo completo', 'Tiempo parcial', 'Aut√≥nomo'], n_samples, p=[0.7, 0.1, 0.2])\n",
    "            zona = np.random.choice(['Urbana', 'Suburbana', 'Rural'], n_samples, p=[0.5, 0.4, 0.1])\n",
    "            \n",
    "            # Variable objetivo (simulada)\n",
    "            # Crear una funci√≥n que determine la decisi√≥n basada en los factores\n",
    "            def simular_decision(ingresos, precio_vivienda, precio_alquiler, tiempo_permanencia, estabilidad_laboral, preferencia_propiedad):\n",
    "                ratio_precio_ingreso = precio_vivienda / (ingresos * 12)\n",
    "                ratio_alquiler_ingreso = precio_alquiler / ingresos\n",
    "                \n",
    "                # Factores que favorecen comprar\n",
    "                puntaje_compra = (\n",
    "                    (tiempo_permanencia > 5) * 2 + \n",
    "                    (estabilidad_laboral > 7) * 1.5 + \n",
    "                    (preferencia_propiedad > 7) * 1.5 + \n",
    "                    (ratio_alquiler_ingreso > 0.3) * 1 - \n",
    "                    (ratio_precio_ingreso > 5) * 2\n",
    "                )\n",
    "                \n",
    "                # A√±adir algo de aleatoriedad\n",
    "                puntaje_compra += np.random.normal(0, 1)\n",
    "                \n",
    "                return 'Comprar' if puntaje_compra > 0 else 'Alquilar'\n",
    "            \n",
    "            decision = [simular_decision(i, pv, pa, tp, el, pp) \n",
    "                       for i, pv, pa, tp, el, pp in zip(ingresos, precio_vivienda, precio_alquiler, \n",
    "                                                       tiempo_permanencia, estabilidad_laboral, preferencia_propiedad)]\n",
    "            \n",
    "            # Crear el DataFrame\n",
    "            df = pd.DataFrame({\n",
    "                'Ingresos_Mensuales': ingresos,\n",
    "                'Precio_Vivienda': precio_vivienda,\n",
    "                'Precio_Alquiler': precio_alquiler,\n",
    "                'Tasa_Interes': tasa_interes,\n",
    "                'Inflacion': inflacion,\n",
    "                'Edad': edad,\n",
    "                'Tiempo_Permanencia_Esperado': tiempo_permanencia,\n",
    "                'Estabilidad_Laboral': estabilidad_laboral,\n",
    "                'Preferencia_Propiedad': preferencia_propiedad,\n",
    "                'Aversion_Riesgo': aversion_riesgo,\n",
    "                'Apreciacion_Propiedad': apreciacion_propiedad,\n",
    "                'Oferta_Vivienda': oferta_vivienda,\n",
    "                'Demanda_Vivienda': demanda_vivienda,\n",
    "                'Tendencia_Mercado': tendencia_mercado,\n",
    "                'Calidad_Ubicacion': calidad_ubicacion,\n",
    "                'Acceso_Servicios': acceso_servicios,\n",
    "                'Distancia_Trabajo': distancia_trabajo,\n",
    "                'Beneficios_Fiscales': beneficios_fiscales,\n",
    "                'Costos_Mantenimiento': costos_mantenimiento,\n",
    "                'Estado_Civil': estado_civil,\n",
    "                'Tiene_Hijos': tiene_hijos,\n",
    "                'Tipo_Empleo': tipo_empleo,\n",
    "                'Zona': zona,\n",
    "                'Decision': decision\n",
    "            })\n",
    "            \n",
    "            print('Datos sint√©ticos creados exitosamente.')\n",
    "except Exception as e:\n",
    "    print(f'Error al cargar los datos: {e}')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bb6809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploraci√≥n inicial de los datos\n",
    "print('üìä Dimensiones del dataset: {}'.format(df.shape))\n",
    "print('üîç Columnas: {}'.format(df.columns.tolist()))\n",
    "\n",
    "# Informaci√≥n b√°sica\n",
    "print('üìã Informaci√≥n del dataset:')\n",
    "df.info()\n",
    "\n",
    "print('üìà Primeras 5 filas:')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48256d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estad√≠sticas descriptivas\n",
    "print('üìä Estad√≠sticas descriptivas:')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648d812d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar valores nulos\n",
    "print('üîç Valores nulos por columna:')\n",
    "nulos = df.isnull().sum()\n",
    "print(nulos[nulos > 0] if nulos.any() > 0 else 'No hay valores nulos en el dataset.')\n",
    "\n",
    "# Distribuci√≥n de la variable objetivo\n",
    "print('üìä Distribuci√≥n de la variable objetivo (Decision):')\n",
    "decision_counts = df['Decision'].value_counts()\n",
    "print(decision_counts)\n",
    "print(f'Porcentaje de Comprar: {decision_counts[\"Comprar\"]/len(df)*100:.2f}%')\n",
    "print(f'Porcentaje de Alquilar: {decision_counts[\"Alquilar\"]/len(df)*100:.2f}%')\n",
    "\n",
    "# Visualizar la distribuci√≥n\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Decision', data=df, palette='viridis')\n",
    "plt.title('Distribuci√≥n de Decisiones: Comprar vs Alquilar', fontsize=14)\n",
    "plt.xlabel('Decisi√≥n', fontsize=12)\n",
    "plt.ylabel('Cantidad', fontsize=12)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "# A√±adir etiquetas con los valores\n",
    "for i, count in enumerate(decision_counts):\n",
    "    plt.text(i, count + 5, f'{count} ({count/len(df)*100:.1f}%)', \n",
    "             ha='center', va='bottom', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7722502b",
   "metadata": {},
   "source": [
    "## 3. An√°lisis Exploratorio de Datos (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc7b8cf",
   "metadata": {},
   "source": [
    "### 3.1 An√°lisis de Variables Num√©ricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330167a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar variables num√©ricas y categ√≥ricas\n",
    "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print(f'Variables num√©ricas ({len(numeric_cols)}): {numeric_cols}')\n",
    "print(f'Variables categ√≥ricas ({len(categorical_cols)}): {categorical_cols}')\n",
    "\n",
    "# Distribuci√≥n de variables num√©ricas clave\n",
    "plt.figure(figsize=(18, 15))\n",
    "\n",
    "# Seleccionar algunas variables num√©ricas importantes para visualizar\n",
    "key_numeric_vars = ['Ingresos_Mensuales', 'Precio_Vivienda', 'Precio_Alquiler', 'Edad', \n",
    "                    'Tiempo_Permanencia_Esperado', 'Estabilidad_Laboral', 'Preferencia_Propiedad']\n",
    "\n",
    "for i, var in enumerate(key_numeric_vars):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    \n",
    "    # Histograma con KDE\n",
    "    sns.histplot(df[var], kde=True, color='skyblue')\n",
    "    \n",
    "    # A√±adir l√≠nea vertical para la media\n",
    "    plt.axvline(df[var].mean(), color='red', linestyle='--', label=f'Media: {df[var].mean():.2f}')\n",
    "    \n",
    "    # A√±adir l√≠nea vertical para la mediana\n",
    "    plt.axvline(df[var].median(), color='green', linestyle='-.', label=f'Mediana: {df[var].median():.2f}')\n",
    "    \n",
    "    plt.title(f'Distribuci√≥n de {var}')\n",
    "    plt.legend(fontsize=8)\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.suptitle('Distribuci√≥n de Variables Num√©ricas Clave', fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf44145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots para detectar outliers en variables num√©ricas clave\n",
    "plt.figure(figsize=(18, 15))\n",
    "\n",
    "for i, var in enumerate(key_numeric_vars):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    \n",
    "    # Boxplot por decisi√≥n\n",
    "    sns.boxplot(x='Decision', y=var, data=df, palette='viridis')\n",
    "    \n",
    "    plt.title(f'Boxplot de {var} por Decisi√≥n')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.suptitle('Boxplots de Variables Num√©ricas por Decisi√≥n', fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea03386",
   "metadata": {},
   "source": [
    "### 3.2 An√°lisis de Variables Categ√≥ricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75cc68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de variables categ√≥ricas\n",
    "plt.figure(figsize=(18, 15))\n",
    "\n",
    "for i, var in enumerate(categorical_cols):\n",
    "    if var != 'Decision':  # Excluimos la variable objetivo\n",
    "        plt.subplot(2, 2, i)\n",
    "        \n",
    "        # Crear tabla de contingencia\n",
    "        cross_tab = pd.crosstab(df[var], df['Decision'])\n",
    "        cross_tab_pct = pd.crosstab(df[var], df['Decision'], normalize='index') * 100\n",
    "        \n",
    "        # Gr√°fico de barras apiladas\n",
    "        cross_tab.plot(kind='bar', stacked=True, ax=plt.gca(), colormap='viridis')\n",
    "        \n",
    "        plt.title(f'Distribuci√≥n de Decisiones por {var}')\n",
    "        plt.xlabel(var)\n",
    "        plt.ylabel('Cantidad')\n",
    "        plt.xticks(rotation=45)\n",
    "        \n",
    "        # A√±adir porcentajes\n",
    "        for j, category in enumerate(cross_tab.index):\n",
    "            for k, decision in enumerate(['Alquilar', 'Comprar']):\n",
    "                if decision in cross_tab.columns:\n",
    "                    plt.text(j, cross_tab.loc[category, 'Alquilar'] + cross_tab.loc[category, 'Comprar']/2 if k == 1 else cross_tab.loc[category, 'Alquilar']/2, \n",
    "                             f'{cross_tab_pct.loc[category, decision]:.1f}%', \n",
    "                             ha='center', va='center', color='white' if k == 0 else 'black', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.suptitle('An√°lisis de Variables Categ√≥ricas vs Decisi√≥n', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865c9b83",
   "metadata": {},
   "source": [
    "### 3.3 An√°lisis de Correlaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276781bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlaci√≥n para variables num√©ricas\n",
    "corr_matrix = df[numeric_cols].corr()\n",
    "\n",
    "# Visualizar la matriz de correlaci√≥n\n",
    "plt.figure(figsize=(14, 12))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))  # M√°scara para mostrar solo la mitad inferior\n",
    "\n",
    "# Crear el mapa de calor\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={'shrink': .8})\n",
    "\n",
    "plt.title('Matriz de Correlaci√≥n de Variables Num√©ricas', fontsize=16)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11040b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar pares de variables con alta correlaci√≥n (|corr| > 0.7)\n",
    "high_corr_pairs = []\n",
    "\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(corr_matrix.iloc[i, j]) > 0.7:\n",
    "            high_corr_pairs.append((corr_matrix.columns[i], corr_matrix.columns[j], corr_matrix.iloc[i, j]))\n",
    "\n",
    "print('Pares de variables con alta correlaci√≥n (|corr| > 0.7):')\n",
    "for var1, var2, corr in high_corr_pairs:\n",
    "    print(f'{var1} - {var2}: {corr:.3f}')\n",
    "\n",
    "# Visualizar las relaciones entre variables altamente correlacionadas\n",
    "if high_corr_pairs:\n",
    "    plt.figure(figsize=(15, 5 * len(high_corr_pairs)))\n",
    "    \n",
    "    for i, (var1, var2, _) in enumerate(high_corr_pairs):\n",
    "        plt.subplot(len(high_corr_pairs), 1, i+1)\n",
    "        \n",
    "        # Scatter plot con l√≠nea de regresi√≥n\n",
    "        sns.regplot(x=var1, y=var2, data=df, scatter_kws={'alpha':0.5}, line_kws={'color':'red'})\n",
    "        \n",
    "        plt.title(f'Relaci√≥n entre {var1} y {var2} (corr = {corr_matrix.loc[var1, var2]:.3f})')\n",
    "        plt.tight_layout()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6ed872",
   "metadata": {},
   "source": [
    "## 4. Preprocesamiento de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0127e9",
   "metadata": {},
   "source": [
    "### 4.1 Codificaci√≥n de Variables Categ√≥ricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b8307b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificaci√≥n de variables categ√≥ricas\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Crear una copia del DataFrame original\n",
    "df_encoded = df.copy()\n",
    "\n",
    "# Codificar la variable objetivo con LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df_encoded['Decision_encoded'] = le.fit_transform(df_encoded['Decision'])\n",
    "print(f'Codificaci√≥n de Decision: {dict(zip(le.classes_, le.transform(le.classes_)))}')\n",
    "\n",
    "# Aplicar One-Hot Encoding a las variables categ√≥ricas (excepto la variable objetivo)\n",
    "categorical_features = [col for col in categorical_cols if col != 'Decision']\n",
    "\n",
    "# Usar pandas get_dummies para One-Hot Encoding\n",
    "df_encoded = pd.get_dummies(df_encoded, columns=categorical_features, drop_first=True)\n",
    "\n",
    "print('Columnas despu√©s de la codificaci√≥n:')\n",
    "print(df_encoded.columns.tolist())\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame codificado\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497e1a4c",
   "metadata": {},
   "source": [
    "### 4.2 Escalado de Caracter√≠sticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c0ab3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaci√≥n de diferentes m√©todos de escalado\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "# Seleccionar variables num√©ricas para escalar\n",
    "numeric_features = df_encoded.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "numeric_features.remove('Decision_encoded')  # Excluir la variable objetivo codificada\n",
    "\n",
    "# Crear DataFrames para cada tipo de escalado\n",
    "df_standard = df_encoded.copy()\n",
    "df_minmax = df_encoded.copy()\n",
    "df_robust = df_encoded.copy()\n",
    "\n",
    "# Aplicar StandardScaler\n",
    "std_scaler = StandardScaler()\n",
    "df_standard[numeric_features] = std_scaler.fit_transform(df_standard[numeric_features])\n",
    "\n",
    "# Aplicar MinMaxScaler\n",
    "minmax_scaler = MinMaxScaler()\n",
    "df_minmax[numeric_features] = minmax_scaler.fit_transform(df_minmax[numeric_features])\n",
    "\n",
    "# Aplicar RobustScaler\n",
    "robust_scaler = RobustScaler()\n",
    "df_robust[numeric_features] = robust_scaler.fit_transform(df_robust[numeric_features])\n",
    "\n",
    "# Visualizar el efecto de los diferentes escaladores en algunas variables clave\n",
    "key_vars_to_plot = ['Ingresos_Mensuales', 'Precio_Vivienda', 'Precio_Alquiler']\n",
    "\n",
    "plt.figure(figsize=(18, 15))\n",
    "\n",
    "for i, var in enumerate(key_vars_to_plot):\n",
    "    # Original data\n",
    "    plt.subplot(4, 3, i+1)\n",
    "    sns.histplot(df[var], kde=True, color='blue')\n",
    "    plt.title(f'Original: {var}')\n",
    "    \n",
    "    # StandardScaler\n",
    "    plt.subplot(4, 3, i+4)\n",
    "    sns.histplot(df_standard[var], kde=True, color='green')\n",
    "    plt.title(f'StandardScaler: {var}')\n",
    "    \n",
    "    # MinMaxScaler\n",
    "    plt.subplot(4, 3, i+7)\n",
    "    sns.histplot(df_minmax[var], kde=True, color='red')\n",
    "    plt.title(f'MinMaxScaler: {var}')\n",
    "    \n",
    "    # RobustScaler\n",
    "    plt.subplot(4, 3, i+10)\n",
    "    sns.histplot(df_robust[var], kde=True, color='purple')\n",
    "    plt.title(f'RobustScaler: {var}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Comparaci√≥n de M√©todos de Escalado', fontsize=16, y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65e9ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar el m√©todo de escalado m√°s apropiado\n",
    "# Para este an√°lisis, usaremos StandardScaler ya que es adecuado para PCA\n",
    "\n",
    "# Crear el DataFrame final para el an√°lisis\n",
    "df_final = df_standard.copy()\n",
    "\n",
    "print('DataFrame final preparado para an√°lisis multivariante.')\n",
    "print(f'Dimensiones: {df_final.shape}')\n",
    "print(f'Columnas: {len(df_final.columns)}')\n",
    "\n",
    "# Guardar los nombres de las caracter√≠sticas para su uso posterior\n",
    "X_features = [col for col in df_final.columns if col != 'Decision' and col != 'Decision_encoded']\n",
    "\n",
    "# Preparar matrices X e y para el an√°lisis\n",
    "X = df_final[X_features].values\n",
    "y = df_final['Decision_encoded'].values\n",
    "\n",
    "print(f'Matriz X: {X.shape}')\n",
    "print(f'Vector y: {y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609b2d47",
   "metadata": {},
   "source": [
    "## 5. An√°lisis de Componentes Principales (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718aa455",
   "metadata": {},
   "source": [
    "### 5.1 Aplicaci√≥n de PCA y An√°lisis de Varianza Explicada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a2dad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar PCA\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Varianza explicada por cada componente\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "cumulative_variance = np.cumsum(explained_variance)\n",
    "\n",
    "# Visualizar la varianza explicada\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Gr√°fico de barras para la varianza explicada por componente\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(range(1, len(explained_variance) + 1), explained_variance, alpha=0.7, color='skyblue')\n",
    "plt.plot(range(1, len(explained_variance) + 1), explained_variance, 'o-', color='red')\n",
    "plt.title('Varianza Explicada por Componente')\n",
    "plt.xlabel('Componente Principal')\n",
    "plt.ylabel('Proporci√≥n de Varianza Explicada')\n",
    "plt.xticks(range(1, len(explained_variance) + 1))\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Gr√°fico de l√≠nea para la varianza acumulada\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, 'o-', color='green')\n",
    "plt.axhline(y=0.8, color='red', linestyle='--', label='80% Varianza')\n",
    "plt.axhline(y=0.9, color='orange', linestyle='--', label='90% Varianza')\n",
    "plt.title('Varianza Acumulada')\n",
    "plt.xlabel('N√∫mero de Componentes')\n",
    "plt.ylabel('Varianza Acumulada')\n",
    "plt.xticks(range(1, len(cumulative_variance) + 1))\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Determinar el n√∫mero √≥ptimo de componentes (80% y 90% de varianza)\n",
    "n_components_80 = np.where(cumulative_variance >= 0.8)[0][0] + 1\n",
    "n_components_90 = np.where(cumulative_variance >= 0.9)[0][0] + 1\n",
    "\n",
    "print(f'N√∫mero de componentes para explicar el 80% de la varianza: {n_components_80}')\n",
    "print(f'N√∫mero de componentes para explicar el 90% de la varianza: {n_components_90}')\n",
    "\n",
    "# Mostrar la varianza explicada por cada componente\n",
    "print('Varianza explicada por cada componente:')\n",
    "for i, var in enumerate(explained_variance[:10]):  # Mostrar solo los primeros 10 componentes\n",
    "    print(f'PC{i+1}: {var:.4f} ({cumulative_variance[i]:.4f} acumulado)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc93f129",
   "metadata": {},
   "source": [
    "### 5.2 An√°lisis de Cargas (Loadings) de los Componentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7428f4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizar las cargas (loadings) de los componentes principales\n",
    "loadings = pca.components_\n",
    "\n",
    "# Crear un DataFrame con las cargas\n",
    "loadings_df = pd.DataFrame(loadings.T, index=X_features, columns=[f'PC{i+1}' for i in range(loadings.shape[0])])\n",
    "\n",
    "# Mostrar las cargas de los primeros 3 componentes\n",
    "print('Cargas de los primeros 3 componentes principales:')\n",
    "loadings_df.iloc[:, :3].sort_values(by='PC1', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a15220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar las cargas de los primeros 3 componentes\n",
    "plt.figure(figsize=(18, 15))\n",
    "\n",
    "for i in range(3):  # Para los primeros 3 componentes\n",
    "    plt.subplot(3, 1, i+1)\n",
    "    \n",
    "    # Ordenar las cargas por valor absoluto\n",
    "    component = loadings_df.iloc[:, i].sort_values(ascending=False)\n",
    "    \n",
    "    # Crear un gr√°fico de barras horizontales\n",
    "    bars = plt.barh(component.index, component.values, color=['red' if x < 0 else 'green' for x in component.values])\n",
    "    \n",
    "    # A√±adir etiquetas con los valores\n",
    "    for bar in bars:\n",
    "        width = bar.get_width()\n",
    "        label_x_pos = width + 0.01 if width > 0 else width - 0.01\n",
    "        plt.text(label_x_pos, bar.get_y() + bar.get_height()/2, f'{width:.3f}', \n",
    "                 va='center', ha='left' if width > 0 else 'right', fontsize=8)\n",
    "    \n",
    "    plt.title(f'Cargas del Componente Principal {i+1}')\n",
    "    plt.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.suptitle('An√°lisis de Cargas de los Componentes Principales', fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b862d438",
   "metadata": {},
   "source": [
    "### 5.3 Visualizaci√≥n de Datos en el Espacio de Componentes Principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2ad416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame con los componentes principales\n",
    "pca_df = pd.DataFrame(X_pca[:, :3], columns=['PC1', 'PC2', 'PC3'])\n",
    "pca_df['Decision'] = df['Decision']\n",
    "\n",
    "# Visualizaci√≥n 2D (PC1 vs PC2)\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Scatter plot con colores por decisi√≥n\n",
    "sns.scatterplot(x='PC1', y='PC2', hue='Decision', data=pca_df, palette='viridis', s=100, alpha=0.7)\n",
    "\n",
    "# A√±adir flechas para las variables originales (biplot)\n",
    "# Seleccionar solo algunas variables importantes para mayor claridad\n",
    "key_features = ['Ingresos_Mensuales', 'Precio_Vivienda', 'Precio_Alquiler', 'Edad', \n",
    "                'Tiempo_Permanencia_Esperado', 'Estabilidad_Laboral', 'Preferencia_Propiedad']\n",
    "\n",
    "# Encontrar los √≠ndices de estas caracter√≠sticas en X_features\n",
    "key_indices = [X_features.index(feat) for feat in key_features if feat in X_features]\n",
    "\n",
    "# Factor de escala para las flechas\n",
    "scale_factor = 5\n",
    "\n",
    "for i in key_indices:\n",
    "    plt.arrow(0, 0, loadings[0, i] * scale_factor, loadings[1, i] * scale_factor, \n",
    "              head_width=0.2, head_length=0.2, fc='blue', ec='blue', alpha=0.6)\n",
    "    plt.text(loadings[0, i] * scale_factor * 1.2, loadings[1, i] * scale_factor * 1.2, \n",
    "             X_features[i], color='blue', ha='center', va='center', fontsize=10)\n",
    "\n",
    "plt.title('Visualizaci√≥n PCA: PC1 vs PC2', fontsize=16)\n",
    "plt.xlabel(f'PC1 ({explained_variance[0]:.2%} varianza)', fontsize=12)\n",
    "plt.ylabel(f'PC2 ({explained_variance[1]:.2%} varianza)', fontsize=12)\n",
    "plt.axhline(y=0, color='gray', linestyle='--', alpha=0.3)\n",
    "plt.axvline(x=0, color='gray', linestyle='--', alpha=0.3)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(title='Decisi√≥n')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
