{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An√°lisis Avanzado de Clasificaci√≥n para Diagn√≥stico de C√°ncer de Mama\n",
    "\n",
    "Este notebook presenta un an√°lisis exhaustivo y avanzado para la clasificaci√≥n de tumores de mama utilizando m√∫ltiples algoritmos de machine learning, t√©cnicas de optimizaci√≥n y validaci√≥n robusta.\n",
    "\n",
    "## Objetivos:\n",
    "- Realizar un an√°lisis exploratorio profundo del dataset\n",
    "- Implementar y comparar m√∫ltiples algoritmos de clasificaci√≥n\n",
    "- Optimizar hiperpar√°metros usando t√©cnicas avanzadas\n",
    "- Evaluar modelos con m√©tricas comprehensivas\n",
    "- Crear visualizaciones interactivas y explicativas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importaci√≥n de Librer√≠as y Configuraci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librer√≠as fundamentales\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Preprocesamiento y selecci√≥n de caracter√≠sticas\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Algoritmos de clasificaci√≥n\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Optimizaci√≥n de hiperpar√°metros\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# M√©tricas de evaluaci√≥n\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                           roc_auc_score, confusion_matrix, classification_report,\n",
    "                           roc_curve, precision_recall_curve, average_precision_score)\n",
    "\n",
    "# Configuraci√≥n\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Configuraci√≥n para reproducibilidad\n",
    "np.random.seed(42)\n",
    "\n",
    "print('‚úÖ Librer√≠as importadas correctamente')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga y Exploraci√≥n Inicial de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset\n",
    "df = pd.read_csv('breast-cancer.csv')\n",
    "\n",
    "print(f'üìä Dimensiones del dataset: {df.shape}')\n",
    "print(f'üîç Columnas: {df.columns.tolist()}')\n",
    "\n",
    "# Informaci√≥n b√°sica\n",
    "print('\\nüìã Informaci√≥n del dataset:')\n",
    "df.info()\n",
    "\n",
    "print('\\nüìà Primeras 5 filas:')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de valores faltantes\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percent = (missing_data / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Columna': missing_data.index,\n",
    "    'Valores_Faltantes': missing_data.values,\n",
    "    'Porcentaje': missing_percent.values\n",
    "}).sort_values('Valores_Faltantes', ascending=False)\n",
    "\n",
    "print('üîç An√°lisis de valores faltantes:')\n",
    "print(missing_df[missing_df['Valores_Faltantes'] > 0])\n",
    "\n",
    "if missing_df['Valores_Faltantes'].sum() == 0:\n",
    "    print('‚úÖ No hay valores faltantes en el dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de la variable objetivo\n",
    "target_counts = df['diagnosis'].value_counts()\n",
    "target_props = df['diagnosis'].value_counts(normalize=True) * 100\n",
    "\n",
    "print('üéØ Distribuci√≥n de la variable objetivo:')\n",
    "for label, count, prop in zip(target_counts.index, target_counts.values, target_props.values):\n",
    "    status = 'Maligno' if label == 'M' else 'Benigno'\n",
    "    print(f'{status} ({label}): {count} casos ({prop:.1f}%)')\n",
    "\n",
    "# Visualizaci√≥n de la distribuci√≥n\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Gr√°fico de barras\n",
    "colors = ['#FF6B6B', '#4ECDC4']\n",
    "target_counts.plot(kind='bar', ax=ax1, color=colors, alpha=0.8)\n",
    "ax1.set_title('Distribuci√≥n de Diagn√≥sticos', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Diagn√≥stico')\n",
    "ax1.set_ylabel('N√∫mero de Casos')\n",
    "ax1.tick_params(axis='x', rotation=0)\n",
    "\n",
    "# Gr√°fico de pastel\n",
    "ax2.pie(target_counts.values, labels=['Maligno', 'Benigno'], colors=colors, \n",
    "        autopct='%1.1f%%', startangle=90)\n",
    "ax2.set_title('Proporci√≥n de Diagn√≥sticos', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. An√°lisis Exploratorio de Datos Avanzado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos para an√°lisis\n",
    "# Eliminar columnas no necesarias\n",
    "if 'id' in df.columns:\n",
    "    df_analysis = df.drop(['id'], axis=1)\n",
    "else:\n",
    "    df_analysis = df.copy()\n",
    "\n",
    "# Separar caracter√≠sticas num√©ricas\n",
    "numeric_features = df_analysis.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "print(f'üìä Caracter√≠sticas num√©ricas encontradas: {len(numeric_features)}')\n",
    "print(f'üî¢ Lista de caracter√≠sticas: {numeric_features[:10]}...')  # Mostrar solo las primeras 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estad√≠sticas descriptivas avanzadas\n",
    "stats_desc = df_analysis[numeric_features].describe()\n",
    "\n",
    "print('üìà Estad√≠sticas descriptivas:')\n",
    "print(stats_desc.round(3))\n",
    "\n",
    "# An√°lisis de asimetr√≠a y curtosis\n",
    "skewness = df_analysis[numeric_features].skew()\n",
    "kurtosis = df_analysis[numeric_features].kurtosis()\n",
    "\n",
    "skew_kurt_df = pd.DataFrame({\n",
    "    'Caracter√≠stica': numeric_features,\n",
    "    'Asimetr√≠a': skewness.values,\n",
    "    'Curtosis': kurtosis.values\n",
    "})\n",
    "\n",
    "print('\\nüìä An√°lisis de distribuci√≥n:')\n",
    "print(skew_kurt_df.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlaci√≥n avanzada\n",
    "correlation_matrix = df_analysis[numeric_features].corr()\n",
    "\n",
    "# Encontrar correlaciones altas\n",
    "high_corr_pairs = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        corr_val = correlation_matrix.iloc[i, j]\n",
    "        if abs(corr_val) > 0.8:\n",
    "            high_corr_pairs.append((\n",
    "                correlation_matrix.columns[i],\n",
    "                correlation_matrix.columns[j],\n",
    "                corr_val\n",
    "            ))\n",
    "\n",
    "print(f'üîó Pares de caracter√≠sticas con alta correlaci√≥n (>0.8): {len(high_corr_pairs)}')\n",
    "for feat1, feat2, corr in high_corr_pairs[:10]:  # Mostrar solo los primeros 10\n",
    "    print(f'  {feat1} - {feat2}: {corr:.3f}')\n",
    "\n",
    "# Visualizaci√≥n de la matriz de correlaci√≥n\n",
    "plt.figure(figsize=(20, 16))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=False, cmap='RdYlBu_r', \n",
    "            center=0, square=True, linewidths=0.5)\n",
    "plt.title('Matriz de Correlaci√≥n de Caracter√≠sticas', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de distribuciones por diagn√≥stico\n",
    "# Seleccionar algunas caracter√≠sticas clave para visualizaci√≥n\n",
    "key_features = ['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', \n",
    "               'smoothness_mean', 'compactness_mean']\n",
    "\n",
    "# Verificar que las caracter√≠sticas existen\n",
    "available_features = [feat for feat in key_features if feat in df_analysis.columns]\n",
    "\n",
    "if len(available_features) < 6:\n",
    "    # Si no tenemos las caracter√≠sticas esperadas, usar las primeras 6 num√©ricas\n",
    "    available_features = numeric_features[:6]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, feature in enumerate(available_features):\n",
    "    # Boxplot\n",
    "    sns.boxplot(data=df_analysis, x='diagnosis', y=feature, ax=axes[i])\n",
    "    axes[i].set_title(f'Distribuci√≥n de {feature}', fontweight='bold')\n",
    "    axes[i].set_xlabel('Diagn√≥stico')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocesamiento y Preparaci√≥n de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar caracter√≠sticas y variable objetivo\n",
    "X = df_analysis[numeric_features]\n",
    "y = df_analysis['diagnosis'].map({'M': 1, 'B': 0})  # Maligno=1, Benigno=0\n",
    "\n",
    "print(f'üìä Forma de X: {X.shape}')\n",
    "print(f'üéØ Forma de y: {y.shape}')\n",
    "print(f'‚úÖ Codificaci√≥n: Maligno=1, Benigno=0')\n",
    "\n",
    "# Divisi√≥n en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f'\\nüìà Conjunto de entrenamiento: {X_train.shape[0]} muestras')\n",
    "print(f'üìä Conjunto de prueba: {X_test.shape[0]} muestras')\n",
    "\n",
    "# Verificar distribuci√≥n en los conjuntos\n",
    "print(f'\\nüéØ Distribuci√≥n en entrenamiento:')\n",
    "print(f'  Maligno: {y_train.sum()} ({y_train.mean()*100:.1f}%)')\n",
    "print(f'  Benigno: {len(y_train)-y_train.sum()} ({(1-y_train.mean())*100:.1f}%)')\n",
    "\n",
    "print(f'\\nüéØ Distribuci√≥n en prueba:')\n",
    "print(f'  Maligno: {y_test.sum()} ({y_test.mean()*100:.1f}%)')\n",
    "print(f'  Benigno: {len(y_test)-y_test.sum()} ({(1-y_test.mean())*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalado de caracter√≠sticas\n",
    "scalers = {\n",
    "    'StandardScaler': StandardScaler(),\n",
    "    'RobustScaler': RobustScaler(),\n",
    "    'MinMaxScaler': MinMaxScaler()\n",
    "}\n",
    "\n",
    "# Aplicar diferentes escaladores\n",
    "scaled_data = {}\n",
    "\n",
    "for name, scaler in scalers.items():\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    scaled_data[name] = {\n",
    "        'X_train': X_train_scaled,\n",
    "        'X_test': X_test_scaled,\n",
    "        'scaler': scaler\n",
    "    }\n",
    "\n",
    "print('‚úÖ Escalado de caracter√≠sticas completado')\n",
    "print(f'üìä Escaladores disponibles: {list(scalers.keys())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Selecci√≥n de Caracter√≠sticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecci√≥n de caracter√≠sticas usando diferentes m√©todos\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Usar StandardScaler para selecci√≥n de caracter√≠sticas\n",
    "X_train_std = scaled_data['StandardScaler']['X_train']\n",
    "X_test_std = scaled_data['StandardScaler']['X_test']\n",
    "\n",
    "# 1. Selecci√≥n univariada (F-score)\n",
    "selector_f = SelectKBest(score_func=f_classif, k=15)\n",
    "X_train_f = selector_f.fit_transform(X_train_std, y_train)\n",
    "X_test_f = selector_f.transform(X_test_std)\n",
    "\n",
    "# 2. Informaci√≥n mutua\n",
    "mi_scores = mutual_info_classif(X_train_std, y_train, random_state=42)\n",
    "mi_features = np.argsort(mi_scores)[-15:]  # Top 15 caracter√≠sticas\n",
    "\n",
    "X_train_mi = X_train_std[:, mi_features]\n",
    "X_test_mi = X_test_std[:, mi_features]\n",
    "\n",
    "# 3. Eliminaci√≥n recursiva de caracter√≠sticas (RFE)\n",
    "rfe_estimator = LogisticRegression(random_state=42, max_iter=1000)\n",
    "rfe_selector = RFE(estimator=rfe_estimator, n_features_to_select=15)\n",
    "X_train_rfe = rfe_selector.fit_transform(X_train_std, y_train)\n",
    "X_test_rfe = rfe_selector.transform(X_test_std)\n",
    "\n",
    "print('‚úÖ Selecci√≥n de caracter√≠sticas completada')\n",
    "print(f'üìä Caracter√≠sticas originales: {X_train_std.shape[1]}')\n",
    "print(f'üîç Caracter√≠sticas seleccionadas: 15')\n",
    "\n",
    "# Mostrar las caracter√≠sticas m√°s importantes seg√∫n F-score\n",
    "feature_names = X.columns\n",
    "f_scores = selector_f.scores_\n",
    "selected_features_f = feature_names[selector_f.get_support()]\n",
    "\n",
    "print(f'\\nüèÜ Top 10 caracter√≠sticas (F-score):')\n",
    "for i, feat in enumerate(selected_features_f[:10]):\n",
    "    score_idx = feature_names.get_loc(feat)\n",
    "    print(f'  {i+1}. {feat}: {f_scores[score_idx]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Implementaci√≥n de M√∫ltiples Algoritmos de Clasificaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir algoritmos de clasificaci√≥n\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),\n",
    "    'SVM': SVC(random_state=42, probability=True),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Neural Network': MLPClassifier(random_state=42, max_iter=1000)\n",
    "}\n",
    "\n",
    "print(f'ü§ñ Algoritmos implementados: {len(classifiers)}')\n",
    "for name in classifiers.keys():\n",
    "    print(f'  ‚Ä¢ {name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para evaluar modelos\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    \"\"\"Eval√∫a un modelo y retorna m√©tricas comprehensivas\"\"\"\n",
    "    \n",
    "    # Entrenar modelo\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicciones\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    \n",
    "    # M√©tricas\n",
    "    metrics = {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1-Score': f1_score(y_test, y_pred),\n",
    "        'ROC-AUC': roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else None\n",
    "    }\n",
    "    \n",
    "    # Validaci√≥n cruzada\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    metrics['CV_Mean'] = cv_scores.mean()\n",
    "    metrics['CV_Std'] = cv_scores.std()\n",
    "    \n",
    "    return metrics, y_pred, y_pred_proba\n",
    "\n",
    "print('‚úÖ Funci√≥n de evaluaci√≥n definida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar todos los modelos con caracter√≠sticas seleccionadas por F-score\n",
    "results = []\n",
    "predictions = {}\n",
    "\n",
    "print('üöÄ Iniciando evaluaci√≥n de modelos...')\n",
    "print('=' * 60)\n",
    "\n",
    "for name, classifier in classifiers.items():\n",
    "    print(f'üìä Evaluando {name}...')\n",
    "    \n",
    "    try:\n",
    "        metrics, y_pred, y_pred_proba = evaluate_model(\n",
    "            classifier, X_train_f, X_test_f, y_train, y_test, name\n",
    "        )\n",
    "        \n",
    "        results.append(metrics)\n",
    "        predictions[name] = {\n",
    "            'y_pred': y_pred,\n",
    "            'y_pred_proba': y_pred_proba\n",
    "        }\n",
    "        \n",
    "        print(f'  ‚úÖ Accuracy: {metrics[\"Accuracy\"]:.4f}')\n",
    "        print(f'  üìà F1-Score: {metrics[\"F1-Score\"]:.4f}')\n",
    "        if metrics['ROC-AUC'] is not None:\n",
    "            print(f'  üéØ ROC-AUC: {metrics[\"ROC-AUC\"]:.4f}')\n",
    "        print()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'  ‚ùå Error: {str(e)}')\n",
    "        print()\n",
    "\n",
    "# Crear DataFrame con resultados\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('Accuracy', ascending=False)\n",
    "\n",
    "print('üèÜ RESULTADOS FINALES:')\n",
    "print('=' * 60)\n",
    "print(results_df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Optimizaci√≥n de Hiperpar√°metros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar los mejores modelos para optimizaci√≥n\n",
    "top_models = results_df.head(3)['Model'].tolist()\n",
    "\n",
    "print(f'üéØ Optimizando hiperpar√°metros para los top 3 modelos:')\n",
    "for i, model in enumerate(top_models, 1):\n",
    "    print(f'  {i}. {model}')\n",
    "\n",
    "# Definir grids de hiperpar√°metros\n",
    "param_grids = {\n",
    "    'Logistic Regression': {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear', 'saga']\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['rbf', 'linear'],\n",
    "        'gamma': ['scale', 'auto', 0.1, 1]\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7]\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizar hiperpar√°metros\n",
    "optimized_models = {}\n",
    "optimization_results = []\n",
    "\n",
    "print('üîß Iniciando optimizaci√≥n de hiperpar√°metros...')\n",
    "print('=' * 60)\n",
    "\n",
    "for model_name in top_models:\n",
    "    if model_name in param_grids:\n",
    "        print(f'‚öôÔ∏è Optimizando {model_name}...')\n",
    "        \n",
    "        # Obtener modelo base\n",
    "        base_model = classifiers[model_name]\n",
    "        \n",
    "        # Grid Search\n",
    "        grid_search = GridSearchCV(\n",
    "            base_model,\n",
    "            param_grids[model_name],\n",
    "            cv=5,\n",
    "            scoring='accuracy',\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X_train_f, y_train)\n",
    "        \n",
    "        # Guardar modelo optimizado\n",
    "        optimized_models[model_name] = grid_search.best_estimator_\n",
    "        \n",
    "        # Evaluar modelo optimizado\n",
    "        opt_metrics, opt_pred, opt_proba = evaluate_model(\n",
    "            grid_search.best_estimator_, X_train_f, X_test_f, y_train, y_test, \n",
    "            f'{model_name} (Optimizado)'\n",
    "        )\n",
    "        \n",
    "        optimization_results.append(opt_metrics)\n",
    "        \n",
    "        print(f'  ‚úÖ Mejor score CV: {grid_search.best_score_:.4f}')\n",
    "        print(f'  üìà Accuracy en test: {opt_metrics[\"Accuracy\"]:.4f}')\n",
    "        print(f'  üéØ Mejores par√°metros: {grid_search.best_params_}')\n",
    "        print()\n",
    "\n",
    "# Crear DataFrame con resultados optimizados\n",
    "if optimization_results:\n",
    "    opt_results_df = pd.DataFrame(optimization_results)\n",
    "    opt_results_df = opt_results_df.sort_values('Accuracy', ascending=False)\n",
    "    \n",
    "    print('üèÜ RESULTADOS DESPU√âS DE OPTIMIZACI√ìN:')\n",
    "    print('=' * 60)\n",
    "    print(opt_results_df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualizaciones Avanzadas y An√°lisis de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaci√≥n visual de modelos\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Accuracy comparison\n",
    "results_df_sorted = results_df.sort_values('Accuracy')\n",
    "axes[0,0].barh(results_df_sorted['Model'], results_df_sorted['Accuracy'], color='skyblue')\n",
    "axes[0,0].set_title('Comparaci√≥n de Accuracy', fontweight='bold')\n",
    "axes[0,0].set_xlabel('Accuracy')\n",
    "\n",
    "# 2. F1-Score comparison\n",
    "results_df_f1 = results_df.sort_values('F1-Score')\n",
    "axes[0,1].barh(results_df_f1['Model'], results_df_f1['F1-Score'], color='lightcoral')\n",
    "axes[0,1].set_title('Comparaci√≥n de F1-Score', fontweight='bold')\n",
    "axes[0,1].set_xlabel('F1-Score')\n",
    "\n",
    "# 3. ROC-AUC comparison (solo modelos con probabilidades)\n",
    "roc_data = results_df.dropna(subset=['ROC-AUC']).sort_values('ROC-AUC')\n",
    "if not roc_data.empty:\n",
    "    axes[1,0].barh(roc_data['Model'], roc_data['ROC-AUC'], color='lightgreen')\n",
    "    axes[1,0].set_title('Comparaci√≥n de ROC-AUC', fontweight='bold')\n",
    "    axes[1,0].set_xlabel('ROC-AUC')\n",
    "\n",
    "# 4. Cross-validation scores\n",
    "cv_data = results_df.sort_values('CV_Mean')\n",
    "axes[1,1].barh(cv_data['Model'], cv_data['CV_Mean'], color='gold')\n",
    "axes[1,1].set_title('Validaci√≥n Cruzada (Media)', fontweight='bold')\n",
    "axes[1,1].set_xlabel('CV Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrices de confusi√≥n para los mejores modelos\n",
    "top_3_models = results_df.head(3)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for i, (_, row) in enumerate(top_3_models.iterrows()):\n",
    "    model_name = row['Model']\n",
    "    \n",
    "    if model_name in predictions:\n",
    "        y_pred = predictions[model_name]['y_pred']\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i],\n",
    "                   xticklabels=['Benigno', 'Maligno'],\n",
    "                   yticklabels=['Benigno', 'Maligno'])\n",
    "        axes[i].set_title(f'{model_name}\\nAccuracy: {row[\"Accuracy\"]:.3f}', fontweight='bold')\n",
    "        axes[i].set_xlabel('Predicci√≥n')\n",
    "        axes[i].set_ylabel('Valor Real')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curvas ROC para modelos con probabilidades\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "colors = ['blue', 'red', 'green', 'orange', 'purple', 'brown', 'pink', 'gray']\n",
    "\n",
    "for i, (model_name, pred_data) in enumerate(predictions.items()):\n",
    "    if pred_data['y_pred_proba'] is not None:\n",
    "        fpr, tpr, _ = roc_curve(y_test, pred_data['y_pred_proba'])\n",
    "        auc_score = roc_auc_score(y_test, pred_data['y_pred_proba'])\n",
    "        \n",
    "        plt.plot(fpr, tpr, color=colors[i % len(colors)], \n",
    "                label=f'{model_name} (AUC = {auc_score:.3f})', linewidth=2)\n",
    "\n",
    "# L√≠nea diagonal (clasificador aleatorio)\n",
    "plt.plot([0, 1], [0, 1], 'k--', alpha=0.5, label='Clasificador Aleatorio')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos (FPR)', fontsize=12)\n",
    "plt.ylabel('Tasa de Verdaderos Positivos (TPR)', fontsize=12)\n",
    "plt.title('Curvas ROC - Comparaci√≥n de Modelos', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. An√°lisis de Importancia de Caracter√≠sticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de importancia para Random Forest (si est√° en top modelos)\n",
    "if 'Random Forest' in [row['Model'] for _, row in results_df.head(3).iterrows()]:\n",
    "    # Entrenar Random Forest para obtener importancias\n",
    "    rf_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "    rf_model.fit(X_train_f, y_train)\n",
    "    \n",
    "    # Obtener importancias\n",
    "    feature_importance = rf_model.feature_importances_\n",
    "    selected_feature_names = selected_features_f\n",
    "    \n",
    "    # Crear DataFrame de importancias\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Caracter√≠stica': selected_feature_names,\n",
    "        'Importancia': feature_importance\n",
    "    }).sort_values('Importancia', ascending=False)\n",
    "    \n",
    "    # Visualizaci√≥n\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(data=importance_df.head(10), x='Importancia', y='Caracter√≠stica', palette='viridis')\n",
    "    plt.title('Top 10 Caracter√≠sticas M√°s Importantes (Random Forest)', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Importancia')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print('üèÜ Top 10 caracter√≠sticas m√°s importantes:')\n",
    "    for i, (_, row) in enumerate(importance_df.head(10).iterrows(), 1):\n",
    "        print(f'  {i}. {row[\"Caracter√≠stica\"]}: {row[\"Importancia\"]:.4f}')\n",
    "\n",
    "else:\n",
    "    print('‚ÑπÔ∏è Random Forest no est√° entre los top 3 modelos para an√°lisis de importancia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. An√°lisis de Errores y Casos L√≠mite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de errores del mejor modelo\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "best_predictions = predictions[best_model_name]\n",
    "\n",
    "print(f'üéØ An√°lisis de errores para: {best_model_name}')\n",
    "print('=' * 50)\n",
    "\n",
    "# Identificar errores\n",
    "y_pred_best = best_predictions['y_pred']\n",
    "errors = y_test != y_pred_best\n",
    "\n",
    "# Falsos positivos y falsos negativos\n",
    "false_positives = (y_test == 0) & (y_pred_best == 1)\n",
    "false_negatives = (y_test == 1) & (y_pred_best == 0)\n",
    "\n",
    "print(f'üìä Total de errores: {errors.sum()} de {len(y_test)} ({errors.mean()*100:.1f}%)')\n",
    "print(f'üî¥ Falsos positivos: {false_positives.sum()} (Benigno predicho como Maligno)')\n",
    "print(f'üî¥ Falsos negativos: {false_negatives.sum()} (Maligno predicho como Benigno)')\n",
    "\n",
    "# An√°lisis de confianza en predicciones\n",
    "if best_predictions['y_pred_proba'] is not None:\n",
    "    y_proba_best = best_predictions['y_pred_proba']\n",
    "    \n",
    "    # Casos con baja confianza (probabilidad cerca de 0.5)\n",
    "    low_confidence = np.abs(y_proba_best - 0.5) < 0.1\n",
    "    \n",
    "    print(f'\\n‚ö†Ô∏è Predicciones con baja confianza: {low_confidence.sum()}')\n",
    "    print(f'   (Probabilidad entre 0.4 y 0.6)')\n",
    "    \n",
    "    # Visualizaci√≥n de distribuci√≥n de probabilidades\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(y_proba_best[y_test == 0], bins=20, alpha=0.7, label='Benigno (Real)', color='blue')\n",
    "    plt.hist(y_proba_best[y_test == 1], bins=20, alpha=0.7, label='Maligno (Real)', color='red')\n",
    "    plt.xlabel('Probabilidad Predicha')\n",
    "    plt.ylabel('Frecuencia')\n",
    "    plt.title('Distribuci√≥n de Probabilidades por Clase Real')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.scatter(range(len(y_proba_best)), y_proba_best, \n",
    "               c=y_test, cmap='RdYlBu', alpha=0.6)\n",
    "    plt.axhline(y=0.5, color='black', linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('√çndice de Muestra')\n",
    "    plt.ylabel('Probabilidad Predicha')\n",
    "    plt.title('Probabilidades Predichas vs Clase Real')\n",
    "    plt.colorbar(label='Clase Real (0=Benigno, 1=Maligno)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conclusiones y Recomendaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen final\n",
    "print('üéØ RESUMEN EJECUTIVO DEL AN√ÅLISIS')\n",
    "print('=' * 60)\n",
    "\n",
    "# Mejor modelo\n",
    "best_model = results_df.iloc[0]\n",
    "print(f'üèÜ MEJOR MODELO: {best_model[\"Model\"]}')\n",
    "print(f'   ‚Ä¢ Accuracy: {best_model[\"Accuracy\"]:.4f} ({best_model[\"Accuracy\"]*100:.1f}%)')\n",
    "print(f'   ‚Ä¢ Precision: {best_model[\"Precision\"]:.4f}')\n",
    "print(f'   ‚Ä¢ Recall: {best_model[\"Recall\"]:.4f}')\n",
    "print(f'   ‚Ä¢ F1-Score: {best_model[\"F1-Score\"]:.4f}')\n",
    "if best_model['ROC-AUC'] is not None:\n",
    "    print(f'   ‚Ä¢ ROC-AUC: {best_model[\"ROC-AUC\"]:.4f}')\n",
    "print(f'   ‚Ä¢ CV Score: {best_model[\"CV_Mean\"]:.4f} ¬± {best_model[\"CV_Std\"]:.4f}')\n",
    "\n",
    "# Top 3 modelos\n",
    "print('ü•á TOP 3 MODELOS:')\n",
    "for i, (_, row) in enumerate(results_df.head(3).iterrows(), 1):\n",
    "    print(f'   {i}. {row[\"Model\"]}: {row[\"Accuracy\"]:.4f} accuracy')\n",
    "\n",
    "# Estad√≠sticas del dataset\n",
    "print('üìä ESTAD√çSTICAS DEL DATASET:')\n",
    "print(f'   ‚Ä¢ Total de muestras: {len(df)}')\n",
    "print(f'   ‚Ä¢ Caracter√≠sticas originales: {len(numeric_features)}')\n",
    "print(f'   ‚Ä¢ Caracter√≠sticas seleccionadas: 15')\n",
    "print(f'   ‚Ä¢ Distribuci√≥n de clases: {(1-y.mean())*100:.1f}% Benigno, {y.mean()*100:.1f}% Maligno')\n",
    "\n",
    "# Recomendaciones\n",
    "print('üí° RECOMENDACIONES:')\n",
    "print('   1. El modelo seleccionado muestra excelente rendimiento para diagn√≥stico')\n",
    "print('   2. Se recomienda validaci√≥n adicional con datos externos')\n",
    "print('   3. Considerar implementaci√≥n en entorno cl√≠nico con supervisi√≥n m√©dica')\n",
    "print('   4. Monitorear continuamente el rendimiento del modelo en producci√≥n')\n",
    "print('   5. Actualizar el modelo peri√≥dicamente con nuevos datos')\n",
    "\n",
    "print('‚úÖ AN√ÅLISIS COMPLETADO EXITOSAMENTE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Exportaci√≥n de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar resultados en archivo CSV\n",
    "results_df.to_csv('resultados_clasificacion_cancer.csv', index=False)\n",
    "\n",
    "# Crear reporte detallado\n",
    "report_data = {\n",
    "    'Fecha_Analisis': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'Dataset_Shape': str(df.shape),\n",
    "    'Mejor_Modelo': best_model['Model'],\n",
    "    'Mejor_Accuracy': best_model['Accuracy'],\n",
    "    'Mejor_F1_Score': best_model['F1-Score'],\n",
    "    'Caracteristicas_Originales': len(numeric_features),\n",
    "    'Caracteristicas_Seleccionadas': 15,\n",
    "    'Modelos_Evaluados': len(classifiers)\n",
    "}\n",
    "\n",
    "report_df = pd.DataFrame([report_data])\n",
    "report_df.to_csv('reporte_analisis_cancer.csv', index=False)\n",
    "\n",
    "print('üíæ Resultados guardados en:')\n",
    "print('   ‚Ä¢ resultados_clasificacion_cancer.csv')\n",
    "print('   ‚Ä¢ reporte_analisis_cancer.csv')\n",
    "\n",
    "print('üéâ ¬°AN√ÅLISIS COMPLETO! üéâ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
   },
   "language_info": {
    "codemirror_mode": {
     "name": "ipython",
     "version": 3
    },
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": "3.8.5"
   }
  },
 "nbformat": 4,
  "nbformat_minor": 4
}