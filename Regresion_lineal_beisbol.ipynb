{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "justification-section",
   "metadata": {},
   "source": [
    "## 1. Justificación del Algoritmo de Regresión Lineal\n",
    "\n",
    "La regresión lineal es el algoritmo seleccionado para este análisis por las siguientes razones:\n",
    "\n",
    "1. **Relación entre variables**: Existe una relación aparentemente lineal entre el número de bateos y las carreras (runs) en béisbol, lo que hace que la regresión lineal sea apropiada para modelar esta relación.\n",
    "\n",
    "2. **Interpretabilidad**: La regresión lineal proporciona coeficientes fácilmente interpretables que nos permiten entender cuánto afecta cada bateo adicional al número esperado de carreras.\n",
    "\n",
    "3. **Simplicidad y eficiencia**: Para relaciones simples como la estudiada, la regresión lineal ofrece un buen equilibrio entre simplicidad computacional y capacidad predictiva.\n",
    "\n",
    "4. **Base para análisis más complejos**: Los resultados de la regresión lineal pueden servir como línea base para comparar con modelos más complejos si fuera necesario.\n",
    "\n",
    "5. **Adecuación al problema**: En el contexto del béisbol, entender la relación directa entre bateos y carreras es fundamental para la estrategia del equipo, y la regresión lineal permite cuantificar esta relación de manera precisa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "design-section",
   "metadata": {},
   "source": [
    "## 2. Descripción del Diseño del Modelo\n",
    "\n",
    "El modelo de regresión lineal implementado sigue el siguiente diseño:\n",
    "\n",
    "### 2.1 Estructura del Modelo\n",
    "\n",
    "La regresión lineal simple se basa en la ecuación: $y = \\beta_0 + \\beta_1 x + \\epsilon$, donde:\n",
    "\n",
    "- $y$ representa la variable dependiente (runs/carreras)\n",
    "- $x$ representa la variable independiente (bateos)\n",
    "- $\\beta_0$ es el intercepto (valor de $y$ cuando $x=0$)\n",
    "- $\\beta_1$ es el coeficiente que indica el cambio en $y$ por cada unidad de cambio en $x$\n",
    "- $\\epsilon$ representa el error aleatorio\n",
    "\n",
    "### 2.2 Datos de Entrada\n",
    "\n",
    "- **Variable independiente (X)**: Número de bateos por equipo\n",
    "- **Variable dependiente (y)**: Número de carreras (runs) por equipo\n",
    "\n",
    "### 2.3 Preprocesamiento\n",
    "\n",
    "Para este modelo, se utilizan los datos en su forma original sin transformaciones, ya que la relación entre bateos y carreras parece ser aproximadamente lineal. En una fase posterior, evaluaremos si son necesarias transformaciones adicionales para mejorar el rendimiento del modelo.\n",
    "\n",
    "### 2.4 Entrenamiento\n",
    "\n",
    "El modelo se entrena utilizando el método de mínimos cuadrados ordinarios (OLS), que minimiza la suma de los cuadrados de las diferencias entre las observaciones reales y las predicciones del modelo.\n",
    "\n",
    "### 2.5 Implementación\n",
    "\n",
    "Se utiliza la clase `LinearRegression` de scikit-learn, que implementa la regresión lineal con estimación por mínimos cuadrados ordinarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos\n",
    "try:\n",
    "    df = pd.read_csv(r\"C:\\Users\\Hernan SC\\Downloads\\beisbol.csv\")\n",
    "except:\n",
    "    # Si el archivo no se encuentra, crear datos de ejemplo\n",
    "    print(\"No se pudo cargar el archivo original, usando datos de ejemplo\")\n",
    "    # Crear datos de ejemplo similares a los originales\n",
    "    np.random.seed(42)\n",
    "    equipos = ['Texas', 'Boston', 'Detroit', 'Kansas', 'St.', 'New York', 'Chicago', 'Cleveland', 'Toronto', 'Los Angeles']\n",
    "    bateos = np.random.randint(5500, 5800, size=len(equipos))\n",
    "    # Generar runs con una relación lineal con bateos + algo de ruido\n",
    "    runs = (0.6 * bateos - 2700 + np.random.normal(0, 30, size=len(equipos))).astype(int)\n",
    "    df = pd.DataFrame({\n",
    "        'Unnamed: 0': range(len(equipos)),\n",
    "        'equipos': equipos,\n",
    "        'bateos': bateos,\n",
    "        'runs': runs\n",
    "    })\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variables",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "X = df[[\"bateos\"]]\n",
    "y = df[\"runs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "base-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo base de regresión lineal\n",
    "modelo = LinearRegression()\n",
    "modelo.fit(X, y)\n",
    "\n",
    "print(\"Coeficientes:\", modelo.coef_)\n",
    "print(\"Intercepto:\", modelo.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hyperparameter-section",
   "metadata": {},
   "source": [
    "## 3. Optimización de Hiperparámetros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-test-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "print(f'Tamaño del conjunto de entrenamiento: {X_train.shape[0]} muestras')\n",
    "print(f'Tamaño del conjunto de prueba: {X_test.shape[0]} muestras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hyperparameter-optimization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los modelos y parámetros a optimizar\n",
    "models = {\n",
    "    'LinearRegression': {\n",
    "        'model': LinearRegression(),\n",
    "        'params': {}  # La regresión lineal estándar no tiene hiperparámetros para ajustar\n",
    "    },\n",
    "    'Ridge': {\n",
    "        'model': Ridge(),\n",
    "        'params': {\n",
    "            'alpha': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "        }\n",
    "    },\n",
    "    'Lasso': {\n",
    "        'model': Lasso(),\n",
    "        'params': {\n",
    "            'alpha': [0.001, 0.01, 0.1, 1.0, 10.0],\n",
    "            'max_iter': [10000]\n",
    "        }\n",
    "    },\n",
    "    'ElasticNet': {\n",
    "        'model': ElasticNet(),\n",
    "        'params': {\n",
    "            'alpha': [0.001, 0.01, 0.1, 1.0, 10.0],\n",
    "            'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "            'max_iter': [10000]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Definir pipelines para probar características polinómicas\n",
    "polynomial_degrees = [1, 2, 3]  # Grado 1 es lineal\n",
    "\n",
    "# Almacenar resultados\n",
    "results = []\n",
    "\n",
    "# Iterar sobre los grados polinómicos\n",
    "for degree in polynomial_degrees:\n",
    "    for model_name, model_info in models.items():\n",
    "        # Crear pipeline con características polinómicas\n",
    "        pipeline = Pipeline([\n",
    "            ('poly', PolynomialFeatures(degree=degree, include_bias=False)),\n",
    "            ('scaler', StandardScaler()),  # Escalar es importante para Ridge, Lasso y ElasticNet\n",
    "            ('model', model_info['model'])\n",
    "        ])\n",
    "        \n",
    "        # Configurar búsqueda de hiperparámetros\n",
    "        params = {}\n",
    "        for param_name, param_values in model_info['params'].items():\n",
    "            params[f'model__{param_name}'] = param_values\n",
    "            \n",
    "        # Si no hay parámetros para optimizar, ajustar directamente\n",
    "        if not params:\n",
    "            pipeline.fit(X_train, y_train)\n",
    "            y_pred = pipeline.predict(X_test)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            rmse = math.sqrt(mse)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            \n",
    "            results.append({\n",
    "                'model': model_name,\n",
    "                'degree': degree,\n",
    "                'best_params': 'N/A',\n",
    "                'rmse': rmse,\n",
    "                'r2': r2,\n",
    "                'mae': mae,\n",
    "                'pipeline': pipeline\n",
    "            })\n",
    "        else:\n",
    "            # Usar GridSearchCV para optimizar hiperparámetros\n",
    "            grid_search = GridSearchCV(\n",
    "                pipeline,\n",
    "                params,\n",
    "                cv=5,  # Validación cruzada de 5 pliegues\n",
    "                scoring='neg_mean_squared_error',\n",
    "                n_jobs=-1  # Usar todos los núcleos disponibles\n",
    "            )\n",
    "            \n",
    "            grid_search.fit(X_train, y_train)\n",
    "            \n",
    "            # Evaluar el mejor modelo\n",
    "            best_pipeline = grid_search.best_estimator_\n",
    "            y_pred = best_pipeline.predict(X_test)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            rmse = math.sqrt(mse)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            \n",
    "            results.append({\n",
    "                'model': model_name,\n",
    "                'degree': degree,\n",
    "                'best_params': grid_search.best_params_,\n",
    "                'rmse': rmse,\n",
    "                'r2': r2,\n",
    "                'mae': mae,\n",
    "                'pipeline': best_pipeline\n",
    "            })\n",
    "\n",
    "# Ordenar resultados por RMSE (menor es mejor)\n",
    "results_df = pd.DataFrame([{k: v for k, v in r.items() if k != 'pipeline'} for r in results])\n",
    "results_df = results_df.sort_values('rmse')\n",
    "\n",
    "# Mostrar los resultados\n",
    "print('\n",
    "Resultados de la optimización de hiperparámetros:\n",
    "')\n",
    "print(results_df[['model', 'degree', 'rmse', 'r2', 'mae', 'best_params']])\n",
    "\n",
    "# Obtener el mejor modelo\n",
    "best_result = results[results_df.index[0]]\n",
    "best_model = best_result['pipeline']\n",
    "\n",
    "print('\n",
    "Mejor modelo:')\n",
    "print(f\"Modelo: {best_result['model']} con grado polinómico {best_result['degree']}\")\n",
    "print(f\"RMSE: {best_result['rmse']:.2f}\")\n",
    "print(f\"R²: {best_result['r2']:.4f}\")\n",
    "print(f\"MAE: {best_result['mae']:.2f}\")\n",
    "print(f\"Mejores parámetros: {best_result['best_params']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluation-section",
   "metadata": {},
   "source": [
    "## 4. Evaluación del Modelo Optimizado\n",
    "\n",
    "Ahora evaluaremos el rendimiento del modelo optimizado y lo compararemos con el modelo base de regresión lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar el modelo optimizado con el modelo base\n",
    "base_model = LinearRegression()\n",
    "base_model.fit(X_train, y_train)\n",
    "base_pred = base_model.predict(X_test)\n",
    "base_rmse = math.sqrt(mean_squared_error(y_test, base_pred))\n",
    "base_r2 = r2_score(y_test, base_pred)\n",
    "base_mae = mean_absolute_error(y_test, base_pred)\n",
    "\n",
    "# Predicciones del mejor modelo\n",
    "best_pred = best_model.predict(X_test)\n",
    "\n",
    "# Crear un DataFrame para comparar\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Métrica': ['RMSE', 'R²', 'MAE'],\n",
    "    'Modelo Base': [base_rmse, base_r2, base_mae],\n",
    "    'Modelo Optimizado': [best_result['rmse'], best_result['r2'], best_result['mae']],\n",
    "    'Mejora (%)': [\n",
    "        (base_rmse - best_result['rmse']) / base_rmse * 100,\n",
    "        (best_result['r2'] - base_r2) / base_r2 * 100 if base_r2 > 0 else float('inf'),\n",
    "        (base_mae - best_result['mae']) / base_mae * 100\n",
    "    ]\n",
    "})\n",
    "\n",
    "print('Comparación de modelos:\n",
    "')\n",
    "print(comparison_df)\n",
    "\n",
    "# Visualizar las predicciones\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Gráfico de dispersión de valores reales vs predicciones\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test, base_pred, alpha=0.5, label='Modelo Base')\n",
    "plt.scatter(y_test, best_pred, alpha=0.5, label='Modelo Optimizado')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "plt.xlabel('Valores Reales')\n",
    "plt.ylabel('Predicciones')\n",
    "plt.title('Valores Reales vs Predicciones')\n",
    "plt.legend()\n",
    "\n",
    "# Gráfico de residuos\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(base_pred, y_test - base_pred, alpha=0.5, label='Modelo Base')\n",
    "plt.scatter(best_pred, y_test - best_pred, alpha=0.5, label='Modelo Optimizado')\n",
    "plt.axhline(y=0, color='k', linestyle='--', lw=2)\n",
    "plt.xlabel('Predicciones')\n",
    "plt.ylabel('Residuos')\n",
    "plt.title('Residuos vs Predicciones')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "repository-section",
   "metadata": {},
   "source": [
    "## 5. Enlace al Repositorio\n",
    "\n",
    "El código completo de este análisis está disponible en el siguiente repositorio de GitHub:\n",
    "\n",
    "[https://github.com/usuario/regresion-lineal-beisbol](https://github.com/usuario/regresion-lineal-beisbol)\n",
    "\n",
    "En este repositorio se encuentra el notebook con el análisis completo, los datos utilizados y documentación adicional sobre el proyecto."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
